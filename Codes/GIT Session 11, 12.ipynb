{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9250cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openai\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "prompt = \"You are a helpful assistant. Answer the following question: Hello, how are you?\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    temperature=0.7,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eddbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n",
    "]\n",
    "\n",
    "# Call the chat completion API\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "# Print the assistant's reply\n",
    "print(response.choices[0].message.content.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New openAI libary has responses.create\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.8,\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a friendly bedtime storyteller for children.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a short bedtime story about a unicorn.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.output_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a6e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat history\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a bedtime storyteller who writes soothing, short stories.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a bedtime story about a unicorn.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Once upon a time, in a forest of moonlight...\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you make it rhyme?\"}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.9,\n",
    "    input=conversation\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f4fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Streaming Responses\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a bedtime storyteller.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a story about a unicorn.\"}\n",
    "    ],\n",
    "    temperature=0.8,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for event in response:\n",
    "    if event.type == \"response.output_text.delta\":\n",
    "        print(event.delta, end=\"\", flush=True) # event.delta contains the partial text that has been streamed so far\n",
    "\n",
    "#After the streaming is complete:\n",
    "final = response.get_final_response()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
